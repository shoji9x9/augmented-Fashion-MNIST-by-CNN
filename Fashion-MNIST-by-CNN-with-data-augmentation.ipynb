{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fashion-MNIST-by-CNN-with-data-augmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"xU6Tc_oTTHII","colab_type":"text"},"cell_type":"markdown","source":["# テーマ：Fashion-MNISTデータセットを畳み込みニューラルネットワーク（CNN）で学習する\n","## 制約\n","* 全体の実行時間は60分以内"]},{"metadata":{"id":"yw_8PaTTTsw6","colab_type":"text"},"cell_type":"markdown","source":["## 今回参考にしたもの\n","* [Get started with TensorFlow 2.0 for experts](https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/advanced.ipynb)"]},{"metadata":{"id":"n_rARdLQr3zQ","colab_type":"text"},"cell_type":"markdown","source":["## 0. Install TensorFlow 2.0"]},{"metadata":{"id":"cG3G4utpTD0C","colab_type":"code","outputId":"ea66252d-2b88-4622-e16f-1ecd1a92cda4","executionInfo":{"status":"ok","timestamp":1556336724182,"user_tz":-540,"elapsed":51491,"user":{"displayName":"Keisuke Shoji","photoUrl":"","userId":"10321049352155053308"}},"colab":{"base_uri":"https://localhost:8080/","height":530}},"cell_type":"code","source":["!pip install tensorflow-gpu==2.0.0-alpha0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0-alpha0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n","\u001b[K    100% |████████████████████████████████| 332.1MB 66kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n","\u001b[K    100% |████████████████████████████████| 419kB 12.5MB/s \n","\u001b[?25hCollecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 27.1MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n","Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n","\u001b[K    100% |████████████████████████████████| 3.0MB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.9.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n","Installing collected packages: tf-estimator-nightly, google-pasta, tb-nightly, tensorflow-gpu\n","Successfully installed google-pasta-0.1.5 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"],"name":"stdout"}]},{"metadata":{"id":"ZYHyNNGpsAY7","colab_type":"text"},"cell_type":"markdown","source":["## 1. Prepare dataset"]},{"metadata":{"id":"uQCnTxM4TIY8","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","#print(tfds.list_builders())\n","dataset, info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)\n","dataset_test, dataset_train = dataset['test'], dataset['train']\n","#print(info)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uzTPgfh7WoP-","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_types(image, label):\n","    image = tf.cast(image, tf.float32)\n","    image /= 255\n","    return image, label\n","\n","batch_size = 32\n","\n","dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\n","dataset_test = dataset_test.map(convert_types).batch(batch_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PqU9JzNxwRmF","colab_type":"text"},"cell_type":"markdown","source":["## 2. Data Augmentation"]},{"metadata":{"id":"fgxq02WjwZE9","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","#datagen = ImageDataGenerator()\n","datagen = ImageDataGenerator(rotation_range = 10, horizontal_flip = True, zoom_range = 0.1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HjpM_PBXsCzt","colab_type":"text"},"cell_type":"markdown","source":["## 3. Define model"]},{"metadata":{"id":"ZKsXTb-1YiX6","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, Flatten, Dense, BatchNormalization, Dropout, Activation, MaxPool2D, GlobalAveragePooling2D\n","from tensorflow.keras import Model\n","\n","class CNNModel(Model):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        drop_rate = 0.5\n","        \n","        self._layers = ([\n","            Conv2D(32, 3), # 28, 28, 1 -> 26, 26, 32\n","            BatchNormalization(),\n","            Activation(tf.nn.relu),\n","            Conv2D(64, 3), # 26, 26, 32 -> 24, 24, 64\n","            BatchNormalization(),\n","            Activation(tf.nn.relu),\n","            MaxPool2D(), # 24, 24, 64 -> 12, 12, 64\n","            Conv2D(128, 3), # 12, 12, 64 -> 10, 10, 128\n","            BatchNormalization(),\n","            Activation(tf.nn.relu),\n","            Conv2D(256, 3), # 10, 10, 128 -> 8, 8, 256\n","            BatchNormalization(),\n","            Activation(tf.nn.relu),\n","            MaxPool2D(), # 8, 8, 256 -> 4, 4, 256\n","            Flatten(), # 4, 4, 256 -> 4096\n","            Dense(256), # 4096 -> 256\n","            BatchNormalization(),\n","            Dropout(drop_rate),\n","            Activation(tf.nn.relu),\n","            Dense(10, activation = 'softmax') # 256 -> 10                        \n","        ])                \n","        \n","    def call(self, x):\n","        for layer in self._layers:\n","            x = layer(x)\n","        return x\n","       \n","    \n","model = CNNModel()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I1CUVBw7f464","colab_type":"code","colab":{}},"cell_type":"code","source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lLyqOWLssNTr","colab_type":"text"},"cell_type":"markdown","source":["## 4. Prepare training"]},{"metadata":{"id":"OPCBWDw0gXJ6","colab_type":"code","colab":{}},"cell_type":"code","source":["train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wVKWF-4MhE2W","colab_type":"code","colab":{}},"cell_type":"code","source":["@tf.function\n","def train_step(image, label):\n","    with tf.GradientTape() as tape:\n","        predictions = model(image)\n","        loss = loss_object(label, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    train_loss(loss)\n","    train_accuracy(label, predictions)\n","        \n","@tf.function\n","def test_step(image, label):\n","    predictions = model(image)\n","    loss = loss_object(label, predictions)\n","    \n","    test_loss(loss)\n","    test_accuracy(label, predictions)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XbV3BADrsTcW","colab_type":"text"},"cell_type":"markdown","source":["## 5. Train"]},{"metadata":{"id":"iQoh1m9oit4-","colab_type":"code","colab":{}},"cell_type":"code","source":["import time\n","\n","num_epoch = 80\n","start_time = time.time()\n","\n","#train_accuracies = []\n","#test_accuracies = []\n","train_accuracies_with_da = []\n","test_accuracies_with_da = []\n","\n","\n","for epoch in range(num_epoch):    \n","    for image, label in dataset_train:\n","        for _image, _label in datagen.flow(image, label, batch_size = batch_size):\n","            train_step(_image, _label)\n","            break\n","        \n","    for test_image, test_label in dataset_test:\n","        test_step(test_image, test_label)\n","        \n","    #train_accuracies.append(train_accuracy.result())\n","    #test_accuracies.append(test_accuracy.result())\n","    train_accuracies_with_da.append(train_accuracy.result())\n","    test_accuracies_with_da.append(test_accuracy.result())\n","    \n","    \n","    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, spent_time: {} min'\n","    spent_time = time.time() - start_time\n","    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100, spent_time / 60))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0f-YXgEN3Hct","colab_type":"text"},"cell_type":"markdown","source":["## 6. Show transition of accuracy"]},{"metadata":{"id":"kNi_-yTD3GwO","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(train_accuracies, label = 'Train Accuracy')\n","plt.plot(test_accuracies, linestyle = 'dashed', label = 'Test Accuracy')\n","plt.plot(train_accuracies_with_da, label = 'Train Accuracy with Data Augmentation')\n","plt.plot(test_accuracies_with_da, linestyle = 'dashed', label = 'Test Accuracy with Data Augmentation')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qRwJ85x5khYy","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}